\section{Discussion}

% ------------- chin --------------------- %
The stroke prediction set revealed important insights into model performance. When the models were applied to the unbalanced data, the results showed high accuracy, but barely predicted any actual strokes (low recall).Which means they usually just guessed “no stroke” every time. Logistic Regression performed best overall as shown in Fig.~\ref{fig:BCM} and table~\ref{tab:stroke_classification_report}, it has a strong recall score of 0.79 for the stroke cases while maintaining a good accuracy. This improvement shows how important it is to deal with unbalanced data when making predictions. The neural network achieved a high accuracy of 92\% but struggled to identify actual stroke cases (low recall), which suggests it had difficulty in learning the patterns of the minority class.

% ------------ luke --------------------- %
The CNN model demonstrated strong performance in classifying brain tumour types. As shown in the confusion matrix (Fig.~\ref{fig:MRICM}), the model correctly identified the majority of cases for each class, with particularly high accuracy for Brain Glioma (284/301) and Brain Meningioma (274/301). Misclassifications were relatively low, though the model tended to confuse Brain Tumour cases with Brain Meningioma (64 instances). Consistent with the classification report, the overall accuracy was 87\%. An activation ablation further indicated that LeakyReLU offered the best generalisation (final validation accuracy approximately 86.5\%), followed by SiLU (approximately 85.5\%) and ReLU (approximately 84.7\%), whereas ELU underperformed (approximately 63.7\% validation accuracy) with a notably higher validation loss. We therefore adopted LeakyReLU in the final CNN, likely benefiting from its small negative slope which mitigates dying-ReLU effects without the instability observed with ELU.

% --------- sar jah ------------------ %
\paragraph{Combined dataset: results and discussion} The experiments exemplify how significantly feature quality influences multiclass disease prediction. Corresponding results in \cite{MLS1,MLS2} indicate that classification using demographic attributes alone does not allow for sound multiclass classification. By contrast, the symptom-based model did a very good job. The model is good at combining different combinations of symptoms (fever, headache, itching) to the appropriate disease (Fungal infection), which has been previously shown in prior work demonstrating the success of Random Forests when diverse, clinically relevant features are present \cite{MLS3,MLS4}. Overall, these results support that Random Forests are stable between tasks, but high-quality clinical/symptom features are vital for multiclass medical prediction as a whole.

% ------------- additional discussion --------------------- %
The results from our work on all three datasets show that model performance is influenced by the data quality, feature representation and class balance. Every dataset presented a distinct issue: classifying images, handling imbalanced stroke predictions or predicting multiple diseases using a mix of demographic and symptom data.

The CNN model for the MRI dataset we used performed well with 87\% accuracy overall and high scores for two of the tumour types. Most of the errors occurred between tumours that look alike, which showed that it was hard to distinguish them based purely on images. The comparison of activation functions revealed that LeakyReLU was the top performer, which highlights that minor architectural choices can noticeably affect a model's ability to generalise when working with limited medical image data.

The stroke prediction results demonstrated the limitations of using classical models on unbalanced clinical data. On the original unbalanced dataset, the models exhibited high accuracy but struggled to identify actual stroke cases, predominantly predicting "no stroke". After applying SMOTE to balance the dataset, Logistic Regression achieved a strong recall of 0.79 for stroke cases with an acceptable accuracy of 0.73. This represents a favourable trade-off in healthcare, as missing a true stroke case is more detrimental than experiencing a minor reduction in overall accuracy. In contrast, the MLP neural network achieved high accuracy (92\%) but it missed most of the actual stroke cases (low recall). This suggests how important it is to handle the class imbalances first when trying to model rare medical cases.

The combined healthcare dataset demonstrated that feature informativeness plays a central role in predicting multiple diseases. When a Random Forest was trained using only demographic and administrative details (such as age or billing information), it failed to distinguish between the six diseases. This confirms that these general attributes are too broad for specific clinical predictions \cite{MLS1,MLS2}. However, when the same model was trained using symptom-based features, it achieved nearly perfect results, demonstrating that the symptoms provided rich and unique information, consistent with findings from other studies \cite{MLS3,MLS4}. This contrast clearly highlights that even the best model will perform poorly if the input features don't have enough clinical relevance.

Furthermore, our experiments demonstrated:
\begin{itemize}
    \item CNNs are highly effective when working with complex images.
    \item Simpler models such as Logistic Regression and Random Forest remain valuable for organised tabular data.
    \item Balancing techniques such as SMOTE are essential for fair evaluations in imbalanced clinical settings.
    \item The quality and clinical relevance of features (such as symptoms) are more important than data volume or model complexity.
\end{itemize}

