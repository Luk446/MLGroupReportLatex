\section{Discussion}

% ------------- chin --------------------- %
The stroke prediction set revealed important insights into model performance. When the models were applied to the unbalanced data, the results showed high accuracy, but barely predicted any actual strokes (low recall).Which means they usually just guessed “no stroke” every time. Logistic Regression performed best overall as shown in Fig.~\ref{fig:BCM} and table~\ref{tab:stroke_classification_report}, it has a strong recall score of 0.79 for the stroke cases while maintaining a good accuracy. This improvement shows how important it is to deal with unbalanced data when making predictions. The neural network achieved a high accuracy of 92\% but struggled to identify actual stroke cases (low recall), which suggests it had difficulty in learning the patterns of the minority class.

% ------------ luke --------------------- %
The CNN model demonstrated strong performance in classifying brain tumor types. As shown in the confusion matrix (Fig.~\ref{fig:MRICM}), the model correctly identified the majority of cases for each class, with particularly high accuracy for Brain Glioma (284/301) and Brain Meningioma (274/301). Misclassifications were relatively low, though the model tended to confuse Brain Tumor cases with Brain Meningioma (64 instances). Consistent with the classification report, the overall accuracy was 87\%. An activation ablation further indicated that LeakyReLU offered the best generalisation (final validation accuracy approximately 86.5\%), followed by SiLU (approximately 85.5\%) and ReLU (approximately 84.7\%), whereas ELU underperformed (approximately 63.7\% validation accuracy) with a notably higher validation loss. We therefore adopted LeakyReLU in the final CNN, likely benefiting from its small negative slope which mitigates dying-ReLU effects without the instability observed with ELU.

% --------- sar jah ------------------ %
\paragraph{Combined dataset: results and discussion} The experiments exemplify how significantly feature quality influences multiclass disease prediction. Corresponding results in \cite{MLS1,MLS2} indicate that classification using demographic attributes alone does not allow for sound multiclass classification. By contrast, the symptom-based model did a very good job. The model is good at combining different combinations of symptoms (fever, headache, itching) to the appropriate disease (Fungal infection), which has been previously shown in prior work demonstrating the success of Random Forests when diverse, clinically relevant features are present \cite{MLS3,MLS4}. Overall, these results support that Random Forests are stable between tasks, but high-quality clinical/symptom features are vital for multiclass medical prediction as a whole.
